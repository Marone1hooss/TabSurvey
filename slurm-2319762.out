

----------------------------------------------------------------------------
Training STG with config/adult.yml in env torch

WARNING:root:imports error 
 You need to install pymongo>=3.9.0 in order to use MongoOutput 
Namespace(config='config/adult.yml', model_name='STG', dataset='Adult', objective='binary', use_gpu=False, gpu_ids=[0, 1], data_parallel=True, optimize_hyperparameters=False, n_trials=2, direction='maximize', num_splits=5, shuffle=True, seed=221, scale=True, target_encode=True, one_hot_encode=False, batch_size=128, val_batch_size=256, early_stopping_rounds=20, epochs=3, logging_period=100, num_features=14, num_classes=1, cat_idx=[1, 3, 5, 6, 7, 8, 9, 13], cat_dims=[9, 16, 7, 15, 6, 5, 2, 42])
Train model with given hyperparameters
Loading dataset Adult...
Dataset loaded!
(32561, 14)
Scaling the data...
Traceback (most recent call last):
  File "/srv/lustre01/project/manapy-um6p-st-msda-1wabcjwe938/users/marwan.housni/TabSurvey/train.py", line 154, in <module>
    main_once(arguments)
  File "/srv/lustre01/project/manapy-um6p-st-msda-1wabcjwe938/users/marwan.housni/TabSurvey/train.py", line 138, in main_once
    sc, time = cross_validation(model, X, y, args)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/srv/lustre01/project/manapy-um6p-st-msda-1wabcjwe938/users/marwan.housni/TabSurvey/train.py", line 44, in cross_validation
    loss_history, val_loss_history = curr_model.fit(X_train, y_train, X_test, y_test)  # X_val, y_val)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/srv/lustre01/project/manapy-um6p-st-msda-1wabcjwe938/users/marwan.housni/TabSurvey/models/stochastic_gates.py", line 34, in fit
    loss, val_loss = self.model.fit(X, y, nr_epochs=self.args.epochs, valid_X=X_val, valid_y=y_val,
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/srv/lustre01/project/manapy-um6p-st-msda-1wabcjwe938/users/marwan.housni/TabSurvey/models/stg_lib/stg.py", line 177, in fit
    return self.train(data_loader, nr_epochs, val_data_loader, verbose, meters, early_stop, print_interval)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/srv/lustre01/project/manapy-um6p-st-msda-1wabcjwe938/users/marwan.housni/TabSurvey/models/stg_lib/stg.py", line 234, in train
    self.train_epoch(data_loader, meters=meters)
  File "/srv/lustre01/project/manapy-um6p-st-msda-1wabcjwe938/users/marwan.housni/TabSurvey/models/stg_lib/stg.py", line 215, in train_epoch
    self.train_step(feed_dict, meters=meters)
  File "/srv/lustre01/project/manapy-um6p-st-msda-1wabcjwe938/users/marwan.housni/TabSurvey/models/stg_lib/stg.py", line 138, in train_step
    loss = as_float(loss)
           ^^^^^^^^^^^^^^
  File "/srv/lustre01/project/manapy-um6p-st-msda-1wabcjwe938/users/marwan.housni/TabSurvey/models/stg_lib/utils.py", line 266, in as_float
    return stmap(_as_float, obj)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/srv/lustre01/project/manapy-um6p-st-msda-1wabcjwe938/users/marwan.housni/TabSurvey/models/stg_lib/utils.py", line 215, in stmap
    elif isinstance(iterable, (collections.Sequence, collections.UserList)):
                               ^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'collections' has no attribute 'Sequence'


----------------------------------------------------------------------------
Training SAINT with config/adult.yml in env torch

WARNING:root:imports error 
 You need to install pymongo>=3.9.0 in order to use MongoOutput 
/home/marwan.housni/.conda/envs/torch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(config='config/adult.yml', model_name='SAINT', dataset='Adult', objective='binary', use_gpu=False, gpu_ids=[0, 1], data_parallel=True, optimize_hyperparameters=False, n_trials=2, direction='maximize', num_splits=5, shuffle=True, seed=221, scale=True, target_encode=True, one_hot_encode=False, batch_size=128, val_batch_size=256, early_stopping_rounds=20, epochs=3, logging_period=100, num_features=14, num_classes=1, cat_idx=[1, 3, 5, 6, 7, 8, 9, 13], cat_dims=[9, 16, 7, 15, 6, 5, 2, 42])
Train model with given hyperparameters
Loading dataset Adult...
Dataset loaded!
(32561, 14)
Scaling the data...
Using dim 32 and batch size 128
Using dim 32 and batch size 128
Epoch 0 loss 0.34254714846611023
Epoch 1 loss 0.3242891728878021
Epoch 2 loss 0.3165605664253235
/home/marwan.housni/.conda/envs/torch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'Log Loss - mean': 0.316083670399325, 'Log Loss - std': 0.0, 'AUC - mean': 0.908105259466896, 'AUC - std': 0.0, 'Accuracy - mean': 0.8450790726239829, 'Accuracy - std': 0.0, 'F1 score - mean': 0.8450790726239829, 'F1 score - std': 0.0}
Using dim 32 and batch size 128
Epoch 0 loss 0.3180905878543854
Epoch 1 loss 0.308616042137146
Epoch 2 loss 0.30063319206237793
/home/marwan.housni/.conda/envs/torch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'Log Loss - mean': 0.30920323757301627, 'Log Loss - std': 0.006880432826308708, 'AUC - mean': 0.9119996852243337, 'AUC - std': 0.003894425757437703, 'Accuracy - mean': 0.8511329024053575, 'Accuracy - std': 0.006053829781374642, 'F1 score - mean': 0.8511329024053575, 'F1 score - std': 0.006053829781374642}
Using dim 32 and batch size 128
Epoch 0 loss 0.3205241560935974
Epoch 1 loss 0.3046376407146454
Epoch 2 loss 0.30538201332092285
/home/marwan.housni/.conda/envs/torch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'Log Loss - mean': 0.30607078338828236, 'Log Loss - std': 0.007154353617936287, 'AUC - mean': 0.9143493576869268, 'AUC - std': 0.004599234285878331, 'Accuracy - mean': 0.8537650962800664, 'Accuracy - std': 0.0061878477035785, 'F1 score - mean': 0.8537650962800664, 'F1 score - std': 0.0061878477035785}
Using dim 32 and batch size 128
Epoch 0 loss 0.3274896740913391
Epoch 1 loss 0.3117057979106903
Epoch 2 loss 0.30468881130218506
/home/marwan.housni/.conda/envs/torch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'Log Loss - mean': 0.3057849316957002, 'Log Loss - std': 0.006215602572423273, 'AUC - mean': 0.9143982865619555, 'AUC - std': 0.003983955210181688, 'Accuracy - mean': 0.8560025691387967, 'Accuracy - std': 0.006613316020172936, 'F1 score - mean': 0.8560025691387967, 'F1 score - std': 0.006613316020172964}
Using dim 32 and batch size 128
Epoch 0 loss 0.3311419188976288
Epoch 1 loss 0.3147357404232025
Epoch 2 loss 0.31123700737953186
{'Log Loss - mean': 0.3068833827991991, 'Log Loss - std': 0.005977737998420757, 'AUC - mean': 0.9137298541521469, 'AUC - std': 0.003805880560306334, 'Accuracy - mean': 0.8558708513798334, 'Accuracy - std': 0.005920992931784839, 'F1 score - mean': 0.8558708513798334, 'F1 score - std': 0.005920992931784865}
Results: {'Log Loss - mean': 0.3068833827991991, 'Log Loss - std': 0.005977737998420757, 'AUC - mean': 0.9137298541521469, 'AUC - std': 0.003805880560306334, 'Accuracy - mean': 0.8558708513798334, 'Accuracy - std': 0.005920992931784839, 'F1 score - mean': 0.8558708513798334, 'F1 score - std': 0.005920992931784865}
Train time: 43.783169951599994
Inference time: 0.8246036731999951
Finished cross validation
{'Log Loss - mean': 0.3068833827991991, 'Log Loss - std': 0.005977737998420757, 'AUC - mean': 0.9137298541521469, 'AUC - std': 0.003805880560306334, 'Accuracy - mean': 0.8558708513798334, 'Accuracy - std': 0.005920992931784839, 'F1 score - mean': 0.8558708513798334, 'F1 score - std': 0.005920992931784865}
(43.783169951599994, 0.8246036731999951)


----------------------------------------------------------------------------
Training RandomForest with config/adult.yml in env sklearn

WARNING:root:imports error 
 You need to install pymongo>=3.9.0 in order to use MongoOutput 
Namespace(config='config/adult.yml', model_name='RandomForest', dataset='Adult', objective='binary', use_gpu=False, gpu_ids=[0, 1], data_parallel=True, optimize_hyperparameters=False, n_trials=2, direction='maximize', num_splits=5, shuffle=True, seed=221, scale=True, target_encode=True, one_hot_encode=False, batch_size=128, val_batch_size=256, early_stopping_rounds=20, epochs=3, logging_period=100, num_features=14, num_classes=1, cat_idx=[1, 3, 5, 6, 7, 8, 9, 13], cat_dims=[9, 16, 7, 15, 6, 5, 2, 42])
Train model with given hyperparameters
Loading dataset Adult...
Dataset loaded!
(32561, 14)
Scaling the data...
{'Log Loss - mean': 0.31024757356090144, 'Log Loss - std': 0.0, 'AUC - mean': 0.9108060629593189, 'AUC - std': 0.0, 'Accuracy - mean': 0.8518347919545525, 'Accuracy - std': 0.0, 'F1 score - mean': 0.8518347919545525, 'F1 score - std': 0.0}
{'Log Loss - mean': 0.30413282837636013, 'Log Loss - std': 0.006114745184541276, 'AUC - mean': 0.9154274026510649, 'AUC - std': 0.004621339691745996, 'Accuracy - mean': 0.8578123591222393, 'Accuracy - std': 0.005977567167686881, 'F1 score - mean': 0.8578123591222393, 'F1 score - std': 0.005977567167686881}
{'Log Loss - mean': 0.2990129592066624, 'Log Loss - std': 0.00879504745548449, 'AUC - mean': 0.9188833074492448, 'AUC - std': 0.006174496711946454, 'Accuracy - mean': 0.8608798200864068, 'Accuracy - std': 0.006529893288780125, 'F1 score - mean': 0.8608798200864068, 'F1 score - std': 0.006529893288780125}
{'Log Loss - mean': 0.2996278025022898, 'Log Loss - std': 0.007690821909438685, 'AUC - mean': 0.9181943144218025, 'AUC - std': 0.0054788175193165945, 'Accuracy - mean': 0.861568955973896, 'Accuracy - std': 0.00577965004013377, 'F1 score - mean': 0.861568955973896, 'F1 score - std': 0.00577965004013377}
{'Log Loss - mean': 0.30006014183601337, 'Log Loss - std': 0.0069330125134821246, 'AUC - mean': 0.9176845329637018, 'AUC - std': 0.005005343311708933, 'Accuracy - mean': 0.8617674497914019, 'Accuracy - std': 0.005184696987432027, 'F1 score - mean': 0.8617674497914019, 'F1 score - std': 0.005184696987432027}
Results: {'Log Loss - mean': 0.30006014183601337, 'Log Loss - std': 0.0069330125134821246, 'AUC - mean': 0.9176845329637018, 'AUC - std': 0.005005343311708933, 'Accuracy - mean': 0.8617674497914019, 'Accuracy - std': 0.005184696987432027, 'F1 score - mean': 0.8617674497914019, 'F1 score - std': 0.005184696987432027}
Train time: 1.6269323885999998
Inference time: 0.08170877920000005
Finished cross validation
{'Log Loss - mean': 0.30006014183601337, 'Log Loss - std': 0.0069330125134821246, 'AUC - mean': 0.9176845329637018, 'AUC - std': 0.005005343311708933, 'Accuracy - mean': 0.8617674497914019, 'Accuracy - std': 0.005184696987432027, 'F1 score - mean': 0.8617674497914019, 'F1 score - std': 0.005184696987432027}
(1.6269323885999998, 0.08170877920000005)


----------------------------------------------------------------------------
Training LinearModel with config/adult.yml in env sklearn

WARNING:root:imports error 
 You need to install pymongo>=3.9.0 in order to use MongoOutput 
/home/marwan.housni/.conda/envs/sklearn/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/marwan.housni/.conda/envs/sklearn/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/marwan.housni/.conda/envs/sklearn/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/marwan.housni/.conda/envs/sklearn/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/marwan.housni/.conda/envs/sklearn/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
Namespace(config='config/adult.yml', model_name='LinearModel', dataset='Adult', objective='binary', use_gpu=False, gpu_ids=[0, 1], data_parallel=True, optimize_hyperparameters=False, n_trials=2, direction='maximize', num_splits=5, shuffle=True, seed=221, scale=True, target_encode=True, one_hot_encode=False, batch_size=128, val_batch_size=256, early_stopping_rounds=20, epochs=3, logging_period=100, num_features=14, num_classes=1, cat_idx=[1, 3, 5, 6, 7, 8, 9, 13], cat_dims=[9, 16, 7, 15, 6, 5, 2, 42])
Train model with given hyperparameters
Loading dataset Adult...
Dataset loaded!
(32561, 14)
Scaling the data...
{'Log Loss - mean': 0.39490576157734353, 'Log Loss - std': 0.0, 'AUC - mean': 0.8458238968609033, 'AUC - std': 0.0, 'Accuracy - mean': 0.8186703516044833, 'Accuracy - std': 0.0, 'F1 score - mean': 0.8186703516044833, 'F1 score - std': 0.0}
{'Log Loss - mean': 0.38835866418498166, 'Log Loss - std': 0.006547097392361895, 'AUC - mean': 0.8503069355515136, 'AUC - std': 0.0044830386906103414, 'Accuracy - mean': 0.8217276819447479, 'Accuracy - std': 0.003057330340264508, 'F1 score - mean': 0.8217276819447479, 'F1 score - std': 0.003057330340264508}
{'Log Loss - mean': 0.3849703975611493, 'Log Loss - std': 0.007178929186984203, 'AUC - mean': 0.8532723065791764, 'AUC - std': 0.0055664418255960075, 'Accuracy - mean': 0.8237705430819204, 'Accuracy - std': 0.0038181246432257014, 'F1 score - mean': 0.8237705430819204, 'F1 score - std': 0.0038181246432257014}
{'Log Loss - mean': 0.3842774307990331, 'Log Loss - std': 0.006331933117460542, 'AUC - mean': 0.8536908092141524, 'AUC - std': 0.0048748732614042395, 'Accuracy - mean': 0.8240241603826934, 'Accuracy - std': 0.0033356441730435955, 'F1 score - mean': 0.8240241603826934, 'F1 score - std': 0.0033356441730435955}
{'Log Loss - mean': 0.3844845996024516, 'Log Loss - std': 0.005678589371986169, 'AUC - mean': 0.8532926492701398, 'AUC - std': 0.004432339880454571, 'Accuracy - mean': 0.8244220310088574, 'Accuracy - std': 0.0030877859025496552, 'F1 score - mean': 0.8244220310088574, 'F1 score - std': 0.003087785902549644}
Results: {'Log Loss - mean': 0.3844845996024516, 'Log Loss - std': 0.005678589371986169, 'AUC - mean': 0.8532926492701398, 'AUC - std': 0.004432339880454571, 'Accuracy - mean': 0.8244220310088574, 'Accuracy - std': 0.0030877859025496552, 'F1 score - mean': 0.8244220310088574, 'F1 score - std': 0.003087785902549644}
Train time: 0.199533404
Inference time: 0.004462921199999981
Finished cross validation
{'Log Loss - mean': 0.3844845996024516, 'Log Loss - std': 0.005678589371986169, 'AUC - mean': 0.8532926492701398, 'AUC - std': 0.004432339880454571, 'Accuracy - mean': 0.8244220310088574, 'Accuracy - std': 0.0030877859025496552, 'F1 score - mean': 0.8244220310088574, 'F1 score - std': 0.003087785902549644}
(0.199533404, 0.004462921199999981)


----------------------------------------------------------------------------
Training ModelTree with config/adult.yml in env gbdt

WARNING:root:imports error 
 You need to install pymongo>=3.9.0 in order to use MongoOutput 
Namespace(config='config/adult.yml', model_name='ModelTree', dataset='Adult', objective='binary', use_gpu=False, gpu_ids=[0, 1], data_parallel=True, optimize_hyperparameters=False, n_trials=2, direction='maximize', num_splits=5, shuffle=True, seed=221, scale=True, target_encode=True, one_hot_encode=False, batch_size=128, val_batch_size=256, early_stopping_rounds=20, epochs=3, logging_period=100, num_features=14, num_classes=1, cat_idx=[1, 3, 5, 6, 7, 8, 9, 13], cat_dims=[9, 16, 7, 15, 6, 5, 2, 42])
Train model with given hyperparameters
Loading dataset Adult...
Dataset loaded!
(32561, 14)
Scaling the data...
Traceback (most recent call last):
  File "/srv/lustre01/project/manapy-um6p-st-msda-1wabcjwe938/users/marwan.housni/TabSurvey/train.py", line 154, in <module>
    main_once(arguments)
  File "/srv/lustre01/project/manapy-um6p-st-msda-1wabcjwe938/users/marwan.housni/TabSurvey/train.py", line 138, in main_once
    sc, time = cross_validation(model, X, y, args)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/srv/lustre01/project/manapy-um6p-st-msda-1wabcjwe938/users/marwan.housni/TabSurvey/train.py", line 44, in cross_validation
    loss_history, val_loss_history = curr_model.fit(X_train, y_train, X_test, y_test)  # X_val, y_val)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/srv/lustre01/project/manapy-um6p-st-msda-1wabcjwe938/users/marwan.housni/TabSurvey/models/modeltree.py", line 28, in fit
    X = np.array(X, dtype=np.float)
                          ^^^^^^^^
  File "/home/marwan.housni/.conda/envs/gbdt/lib/python3.11/site-packages/numpy/__init__.py", line 324, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'float'.
`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'cfloat'?


----------------------------------------------------------------------------
Training NAM with config/adult.yml in env torch

WARNING:root:imports error 
 You need to install pymongo>=3.9.0 in order to use MongoOutput 
Namespace(config='config/adult.yml', model_name='NAM', dataset='Adult', objective='binary', use_gpu=False, gpu_ids=[0, 1], data_parallel=True, optimize_hyperparameters=False, n_trials=2, direction='maximize', num_splits=5, shuffle=True, seed=221, scale=True, target_encode=True, one_hot_encode=False, batch_size=128, val_batch_size=256, early_stopping_rounds=20, epochs=3, logging_period=100, num_features=14, num_classes=1, cat_idx=[1, 3, 5, 6, 7, 8, 9, 13], cat_dims=[9, 16, 7, 15, 6, 5, 2, 42])
Train model with given hyperparameters
Loading dataset Adult...
Dataset loaded!
(32561, 14)
Scaling the data...
Traceback (most recent call last):
  File "/srv/lustre01/project/manapy-um6p-st-msda-1wabcjwe938/users/marwan.housni/TabSurvey/train.py", line 154, in <module>
    main_once(arguments)
  File "/srv/lustre01/project/manapy-um6p-st-msda-1wabcjwe938/users/marwan.housni/TabSurvey/train.py", line 133, in main_once
    model_name = str2model(args.model_name)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/srv/lustre01/project/manapy-um6p-st-msda-1wabcjwe938/users/marwan.housni/TabSurvey/models/__init__.py", line 81, in str2model
    from models.neural_additive_models import NAM
  File "/srv/lustre01/project/manapy-um6p-st-msda-1wabcjwe938/users/marwan.housni/TabSurvey/models/neural_additive_models.py", line 4, in <module>
    from nam.config import defaults
ModuleNotFoundError: No module named 'nam'


----------------------------------------------------------------------------
Training LightGBM with config/adult.yml in env gbdt

WARNING:root:imports error 
 You need to install pymongo>=3.9.0 in order to use MongoOutput 
/home/marwan.housni/.conda/envs/gbdt/lib/python3.11/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.
  _log_warning('Overriding the parameters from Reference Dataset.')
/home/marwan.housni/.conda/envs/gbdt/lib/python3.11/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.
  _log_warning(f'{cat_alias} in param dict is overridden.')
/home/marwan.housni/.conda/envs/gbdt/lib/python3.11/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.
  _log_warning('Overriding the parameters from Reference Dataset.')
/home/marwan.housni/.conda/envs/gbdt/lib/python3.11/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.
  _log_warning(f'{cat_alias} in param dict is overridden.')
/home/marwan.housni/.conda/envs/gbdt/lib/python3.11/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.
  _log_warning('Overriding the parameters from Reference Dataset.')
/home/marwan.housni/.conda/envs/gbdt/lib/python3.11/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.
  _log_warning(f'{cat_alias} in param dict is overridden.')
/home/marwan.housni/.conda/envs/gbdt/lib/python3.11/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.
  _log_warning('Overriding the parameters from Reference Dataset.')
/home/marwan.housni/.conda/envs/gbdt/lib/python3.11/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.
  _log_warning(f'{cat_alias} in param dict is overridden.')
/home/marwan.housni/.conda/envs/gbdt/lib/python3.11/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.
  _log_warning('Overriding the parameters from Reference Dataset.')
/home/marwan.housni/.conda/envs/gbdt/lib/python3.11/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.
  _log_warning(f'{cat_alias} in param dict is overridden.')
Namespace(config='config/adult.yml', model_name='LightGBM', dataset='Adult', objective='binary', use_gpu=False, gpu_ids=[0, 1], data_parallel=True, optimize_hyperparameters=False, n_trials=2, direction='maximize', num_splits=5, shuffle=True, seed=221, scale=True, target_encode=True, one_hot_encode=False, batch_size=128, val_batch_size=256, early_stopping_rounds=20, epochs=3, logging_period=100, num_features=14, num_classes=1, cat_idx=[1, 3, 5, 6, 7, 8, 9, 13], cat_dims=[9, 16, 7, 15, 6, 5, 2, 42])
Train model with given hyperparameters
Loading dataset Adult...
Dataset loaded!
(32561, 14)
Scaling the data...
Training until validation scores don't improve for 20 rounds
Did not meet early stopping. Best iteration is:
[2]	eval's auc: 0.896125
{'Log Loss - mean': 0.5319043205643598, 'Log Loss - std': 0.0, 'AUC - mean': 0.8961249358010481, 'AUC - std': 0.0, 'Accuracy - mean': 0.7590971902349147, 'Accuracy - std': 0.0, 'F1 score - mean': 0.7590971902349147, 'F1 score - std': 0.0}
Training until validation scores don't improve for 20 rounds
Did not meet early stopping. Best iteration is:
[3]	eval's auc: 0.899139
{'Log Loss - mean': 0.5268965814725322, 'Log Loss - std': 0.005007739091827668, 'AUC - mean': 0.8976320541543217, 'AUC - std': 0.001507118353273551, 'Accuracy - mean': 0.759155474724337, 'Accuracy - std': 5.828448942224451e-05, 'F1 score - mean': 0.759155474724337, 'F1 score - std': 5.828448942224451e-05}
Training until validation scores don't improve for 20 rounds
Did not meet early stopping. Best iteration is:
[3]	eval's auc: 0.904335
{'Log Loss - mean': 0.5249603723575763, 'Log Loss - std': 0.004920986894403297, 'AUC - mean': 0.8998664531837103, 'AUC - std': 0.003391068936522489, 'Accuracy - mean': 0.7591749028874778, 'Accuracy - std': 5.495114361128626e-05, 'F1 score - mean': 0.7591749028874778, 'F1 score - std': 5.495114361128626e-05}
Training until validation scores don't improve for 20 rounds
Did not meet early stopping. Best iteration is:
[3]	eval's auc: 0.898927
{'Log Loss - mean': 0.5241320437416803, 'Log Loss - std': 0.004496717569394689, 'AUC - mean': 0.8996314706317066, 'AUC - std': 0.002964820702576192, 'Accuracy - mean': 0.7591846169690482, 'Accuracy - std': 5.047584848626914e-05, 'F1 score - mean': 0.7591846169690482, 'F1 score - std': 5.047584848626914e-05}
Training until validation scores don't improve for 20 rounds
Did not meet early stopping. Best iteration is:
[3]	eval's auc: 0.892169
{'Log Loss - mean': 0.5238280361918439, 'Log Loss - std': 0.004067684535525391, 'AUC - mean': 0.8981389020890453, 'AUC - std': 0.003992890288613877, 'Accuracy - mean': 0.7591904454179904, 'Accuracy - std': 4.662759153779561e-05, 'F1 score - mean': 0.7591904454179904, 'F1 score - std': 4.662759153779561e-05}
Results: {'Log Loss - mean': 0.5238280361918439, 'Log Loss - std': 0.004067684535525391, 'AUC - mean': 0.8981389020890453, 'AUC - std': 0.003992890288613877, 'Accuracy - mean': 0.7591904454179904, 'Accuracy - std': 4.662759153779561e-05, 'F1 score - mean': 0.7591904454179904, 'F1 score - std': 4.662759153779561e-05}
Train time: 0.08132565120000006
Inference time: 0.005016681200000006
Finished cross validation
{'Log Loss - mean': 0.5238280361918439, 'Log Loss - std': 0.004067684535525391, 'AUC - mean': 0.8981389020890453, 'AUC - std': 0.003992890288613877, 'Accuracy - mean': 0.7591904454179904, 'Accuracy - std': 4.662759153779561e-05, 'F1 score - mean': 0.7591904454179904, 'F1 score - std': 4.662759153779561e-05}
(0.08132565120000006, 0.005016681200000006)


----------------------------------------------------------------------------
Training DeepGBM with config/adult.yml in env torch

WARNING:root:imports error 
 You need to install pymongo>=3.9.0 in order to use MongoOutput 
/srv/lustre01/project/manapy-um6p-st-msda-1wabcjwe938/users/marwan.housni/TabSurvey/models/deepgbm_lib/utils/helper.py:52: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/conda/conda-bld/pytorch_1708025569485/work/torch/csrc/utils/python_arg_parser.cpp:1630.)
  p.data.add_(-self.weight_decay, p.data)
slurmstepd-slurm-compute-h21a8-u7-svn4: error: *** JOB 2319762 ON slurm-compute-h21a8-u7-svn4 CANCELLED AT 2024-03-18T15:34:48 ***
